{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "class Signs:\n",
    "    \"\"\"\n",
    "    Class to store MNIST data\n",
    "    \"\"\"\n",
    "    def __init__(self, location):\n",
    "\n",
    "        import pickle, gzip, collections\n",
    "\n",
    "        # load data from file \n",
    "        #data = pd.read_csv(location, 'rb',engine='python',index_col=0)\n",
    "        #X = data.drop(['label'], axis=0, inplace=True)\n",
    "        #y = data[\"label\"].values\n",
    "        data = pd.read_csv(\"data/sign_mnist_train.csv\")\n",
    "        self.train_x = data.drop(columns = \"label\").values\n",
    "        self.train_y = data[\"label\"].values\n",
    "        data = pd.read_csv(\"data/sign_mnist_test.csv\")\n",
    "        self.test_x = data.drop(columns = \"label\").values\n",
    "        self.test_y = data[\"label\"].values\n",
    "        print(\"Lenght of training data is \", len(self.train_x))\n",
    "        print(\"Lenght of testing data is \", len(self.test_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lenght of training data is  27455\n",
      "Lenght of testing data is  7172\n"
     ]
    }
   ],
   "source": [
    "DATA_PATH = \"data/sign_mnist_train.csv\"\n",
    "data = Signs(DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######## Label is  2\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "def view_sign(example, label):\n",
    "    plt.imshow(example.reshape(28,28))\n",
    "    print(\"######## Label is \", label)\n",
    "view_sign(data.train_x[2],data.train_y[2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "def sift(img, class_number):\n",
    "    \"\"\"\n",
    "    Gets a list of 128 - dimensional descriptors using SIFT and DoG\n",
    "    for keypoints and resizes the image having the larger dimension set to 640\n",
    "    and keeping the size relation.\n",
    "    Args:\n",
    "        img (BGR matrix): The grayscale image that will be used.\n",
    "    Returns:\n",
    "        list of floats array: The descriptors found in the image.\n",
    "    \"\"\"\n",
    "    img_descs = []\n",
    "    y = []\n",
    "    sift = cv2.xfeatures2d.SIFT_create()\n",
    "    kp, des = sift.detectAndCompute(img, None)\n",
    "    if des is not None:\n",
    "        #print(\"shape of des \", np.shape(des))\n",
    "        img_descs.append(des)\n",
    "        y.append(class_number)\n",
    "    else:\n",
    "        #print('Found empty for label !!!!!!!', class_number)\n",
    "        img_descs.append(np.zeros(128))\n",
    "        y.append(class_number)\n",
    "        #return None\n",
    "    #print(\"shape of sift \", np.shape(img_descs))\n",
    "    #print(\"label here is---------\", y)\n",
    "    return img_descs,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "def extract_features(data_x, data_y):\n",
    "    des = None\n",
    "    i = 0\n",
    "    empty = 0\n",
    "    for d in data_x:\n",
    "        #print(\"----------- at i \", i)\n",
    "        fname = \"img{}\".format(i)+\".jpg\"\n",
    "        cv2.imwrite(fname, d.reshape(28,28))\n",
    "        img = cv2.imread(fname)\n",
    "        os.remove(fname)\n",
    "        gray= cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        #print(\"label is \\n\", data.train_y[i])\n",
    "        new_des = sift(gray, data_y[i])\n",
    "        #print(\"type is \", new_des[0])\n",
    "        #print(\"type is \", type(np.array(new_des[0])))\n",
    "        if not np.array(new_des[0]).any():\n",
    "            empty = empty+1\n",
    "        if new_des is not None:\n",
    "            if des is None:\n",
    "                des = np.array(new_des)\n",
    "                des = np.transpose(des)\n",
    "                #print(\"shape of des here --------\", np.shape(des))\n",
    "                #print(des[1])\n",
    "            else:\n",
    "                #print(\"shape from sift \\n\", np.shape(new_des))\n",
    "                #print(\"label from func \\n\", new_des[1])\n",
    "                des = np.vstack((des, np.array(np.transpose(new_des))))\n",
    "                #print(\"shape of des here --------\", np.shape(des))\n",
    "                #des = np.transpose(des)\n",
    "                #print(\"shape of des here --------\", np.shape(des))\n",
    "        else:\n",
    "            empty = empty+1\n",
    "            print(np.shape(des))\n",
    "            print(np.shape(np.zeros(128)))\n",
    "            #des = np.vstack((des, np.zeros(128)))\n",
    "        i = i+1\n",
    "        #if (i==100):\n",
    "            #break\n",
    "    print(\"No. of images for which sift returned None \", empty) \n",
    "    return des\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of images for which sift returned None  69\n"
     ]
    }
   ],
   "source": [
    "des = extract_features(data.train_x, data.train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "descrptor shape is  (184773, 128)\n",
      "24\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "def extract_descriptors(des):\n",
    "    descriptors = None\n",
    "    for d in des:\n",
    "        #print (\"shape is \", np.shape(d[0]))\n",
    "        #print(\"labe is \", d[1])\n",
    "        if descriptors is None:\n",
    "            descriptors = np.array(d[0])\n",
    "            #print(\"descrptor shape in loop is \", np.shape(descriptors))\n",
    "        else:\n",
    "            #print(\"descrptor shape in loop before vstack is \", np.shape(descriptors))\n",
    "            descriptors = np.vstack((descriptors, d[0]))\n",
    "            #print(\"descrptor shape in loop after vstack is \", np.shape(descriptors))\n",
    "    return descriptors\n",
    "    \n",
    "descriptors = extract_descriptors(des)\n",
    "print(\"descrptor shape is \", np.shape(descriptors))\n",
    "'''for d in des:\n",
    "    print(np.shape(d[0]))\n",
    "    print(\"orig d\", d)\n",
    "    \n",
    "    #print(np.shape(list(d)))\n",
    "    print(\"after flatten \", np.hstack(d[0]))\n",
    "    print(\"len \", len(np.hstack(d[0])))'''\n",
    "'''print(np.shape(des[0]))\n",
    "print(np.shape(des[0][0]))\n",
    "print(np.shape(des[1][0]))\n",
    "print(np.shape(des[2][0]))\n",
    "print(des[1][1])'''\n",
    "k = 24  # Number of clusters\n",
    "kmeans_sift = KMeans(n_clusters=k).fit(descriptors)\n",
    "print(len(kmeans_sift.cluster_centers_))\n",
    "\n",
    "#print(\"train labels \", kmeans.labels_)\n",
    "#voc, variance = kmeans(des, k, 1)  # Perform Kmeans with default values\n",
    "#descriptors = des_list[0][0]\n",
    "\n",
    "#for image_path, descriptor in des_list[:0]:\n",
    "    #print(descriptor)\n",
    "    #descriptors = np.vstack((descriptors, descriptor))  # Stacking the descriptors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of images for which sift returned None  8\n",
      "descrptor shape is  (47883, 128)\n"
     ]
    }
   ],
   "source": [
    "des_test = extract_features(data.test_x, data.test_y)\n",
    "\n",
    "descriptors = extract_descriptors(des_test)\n",
    "print(\"descrptor shape is \", np.shape(descriptors))\n",
    "result_sift_kmeans = kmeans_sift.predict(descriptors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "def majority(neighbor_indices, counts):\n",
    "        \"\"\"\n",
    "        Given the indices of training protypes, return the majority label. Break ties \n",
    "        by choosing the tied label that appears most often in the training prototypes. \n",
    "\n",
    "        :param neighbor_indices: The indices of the k nearest neighbors\n",
    "        \"\"\"\n",
    "        #assert len(neighbor_indices) == self._k, \"Did not get k neighbor indices\"\n",
    "        if len(neighbor_indices) == 0:\n",
    "            return -1\n",
    "        #Get labels of neighbor indices\n",
    "        y_neighbors = neighbor_indices\n",
    "        \n",
    "        #Get count of each label of neighbors\n",
    "        label_counters = collections.Counter(y_neighbors)\n",
    "        \n",
    "        #assign first label as majority label\n",
    "        majority_label = y_neighbors[0]\n",
    "        \n",
    "        for label in label_counters.keys():\n",
    "            if (label_counters[label] > label_counters[majority_label]):\n",
    "                majority_label = label\n",
    "            elif label_counters[label] == label_counters[majority_label]:\n",
    "                #in case there is still a tie, just choose label as the majority_label\n",
    "                if counts[label] >= counts[majority_label]:\n",
    "                    majority_label = label\n",
    "\n",
    "        return majority_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy_cluster(expected, predicted):\n",
    "    label_count_map = {}\n",
    "    for true_label, pred_label in zip(expected, predicted):\n",
    "        key = \"p\" + str(pred_label) + \"e\"  + str(true_label)\n",
    "        if key in label_count_map:\n",
    "            label_count_map[key] = label_count_map[key]+1\n",
    "        else:\n",
    "            label_count_map[key] = 1\n",
    "    print(label_count_map)\n",
    "    import collections\n",
    "    od = collections.OrderedDict(sorted(label_count_map.items()))\n",
    "    print(od)\n",
    "    final_label_map = {}\n",
    "    final_label_count_map = {}\n",
    "    for key, value in od.items():\n",
    "        #print(key, value)\n",
    "        pred_label = \"\"\n",
    "        true_label = \"\"\n",
    "        e_flag = 0\n",
    "        for k in range(0, len(key)):\n",
    "            if key[k] != \"p\" and key[k] != \"e\" and e_flag == 0:\n",
    "               pred_label = pred_label+key[k]\n",
    "            elif key[k] != \"p\" and key[k] != \"e\" and e_flag == 1:\n",
    "               true_label = true_label+key[k]\n",
    "            elif key[k] == \"e\":\n",
    "                e_flag = 1\n",
    "        #print(\"pred is \", pred_label+ \", true is \" + true_label)\n",
    "        if pred_label not in final_label_map:\n",
    "            final_label_count_map[pred_label] = value\n",
    "            final_label_map[pred_label] = true_label\n",
    "        elif final_label_count_map[pred_label] <= value:\n",
    "            final_label_count_map[pred_label] = value\n",
    "            final_label_map[pred_label] = true_label\n",
    "\n",
    "    print(\"final map is \", final_label_map)\n",
    "    err = 0\n",
    "    for true_label, pred_label in zip(expected, predicted):\n",
    "        #print(pred_label)\n",
    "        if final_label_map[str(pred_label)] != str(true_label):\n",
    "            err = err +1\n",
    "    #print(\"Total errors \", err)  \n",
    "    return 100- err*100/len(predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'p9e3': 1, 'p7e21': 1, 'p3e3': 2, 'p9e17': 1, 'p3e13': 3, 'p7e2': 2, 'p7e15': 4, 'p8e8': 1, 'p9e6': 2, 'p0e14': 1, 'p6e22': 4, 'p6e13': 1, 'p-1e14': 226, 'p2e8': 2, 'p2e13': 3, 'p3e1': 2, 'p3e11': 1, 'p9e14': 1, 'p9e0': 1, 'p-1e18': 229, 'p3e20': 4, 'p6e17': 4, 'p7e18': 1, 'p8e0': 1, 'p2e20': 2, 'p7e11': 1, 'p8e18': 3, 'p-1e6': 326, 'p7e7': 2, 'p2e11': 2, 'p-1e13': 277, 'p2e7': 5, 'p6e5': 5, 'p8e3': 2, 'p7e22': 1, 'p3e0': 2, 'p9e15': 2, 'p3e15': 2, 'p3e17': 1, 'p2e5': 3, 'p-1e16': 155, 'p7e12': 4, 'p8e22': 1, 'p2e22': 3, 'p2e12': 2, 'p2e4': 8, 'p4e17': 1, 'p-1e20': 251, 'p6e10': 6, 'p4e22': 2, 'p5e21': 1, 'p7e6': 2, 'p7e24': 3, 'p9e7': 1, 'p4e21': 6, 'p-1e22': 193, 'p9e22': 1, 'p6e4': 11, 'p4e11': 1, 'p5e8': 1, 'p4e6': 4, 'p4e5': 3, 'p2e10': 2, 'p-1e4': 468, 'p-1e19': 232, 'p2e6': 3, 'p8e10': 2, 'p9e21': 1, 'p0e15': 1, 'p6e15': 8, 'p7e17': 1, 'p2e21': 3, 'p9e10': 4, 'p-1e23': 249, 'p2e17': 1, 'p-1e11': 200, 'p3e2': 1, 'p7e8': 4, 'p-1e7': 407, 'p-1e8': 267, 'p4e8': 4, 'p3e23': 1, 'p4e13': 5, 'p3e10': 2, 'p9e2': 2, 'p9e13': 2, 'p4e23': 1, 'p4e18': 2, 'p2e2': 4, 'p3e8': 1, 'p-1e10': 309, 'p3e12': 3, 'p2e15': 4, 'p4e12': 3, 'p6e6': 8, 'p6e11': 4, 'p5e4': 1, 'p-1e17': 135, 'p6e1': 10, 'p-1e12': 369, 'p6e2': 6, 'p9e16': 2, 'p3e24': 2, 'p4e14': 4, 'p4e10': 4, 'p7e23': 2, 'p9e19': 4, 'p9e18': 1, 'p3e21': 1, 'p3e7': 3, 'p-1e15': 320, 'p9e1': 4, 'p6e3': 8, 'p4e19': 3, 'p2e3': 4, 'p3e6': 1, 'p9e4': 1, 'p5e12': 2, 'p0e6': 1, 'p7e10': 1, 'p3e16': 1, 'p3e14': 3, 'p-1e0': 315, 'p3e4': 2, 'p8e6': 1, 'p-1e24': 310, 'p5e0': 2, 'p2e1': 3, 'p2e23': 3, 'p4e0': 5, 'p2e14': 2, 'p-1e1': 403, 'p-1e21': 317, 'p7e4': 4, 'p8e14': 1, 'p6e20': 2, 'p6e8': 8, 'p5e10': 1, 'p6e12': 7, 'p4e4': 3, 'p4e15': 6, 'p2e24': 3, 'p6e24': 6, 'p3e5': 1, 'p6e21': 14, 'p2e18': 2, 'p4e7': 4, 'p4e1': 5, 'p6e7': 13, 'p4e24': 5, 'p8e12': 2, 'p7e5': 2, 'p6e19': 6, 'p4e3': 3, 'p6e18': 8, 'p6e16': 4, 'p0e7': 1, 'p2e19': 2, 'p2e0': 2, 'p3e22': 1, 'p9e12': 2, 'p9e23': 2, 'p-1e5': 232, 'p8e24': 2, 'p9e20': 2, 'p8e21': 2, 'p7e1': 5, 'p9e24': 1, 'p-1e2': 289, 'p6e14': 8, 'p0e20': 1, 'p4e20': 4, 'p2e16': 1, 'p-1e3': 223, 'p4e2': 6, 'p6e23': 9, 'p5e3': 2, 'p3e19': 1, 'p8e5': 1, 'p7e16': 1, 'p6e0': 3}\n",
      "OrderedDict([('p-1e0', 315), ('p-1e1', 403), ('p-1e10', 309), ('p-1e11', 200), ('p-1e12', 369), ('p-1e13', 277), ('p-1e14', 226), ('p-1e15', 320), ('p-1e16', 155), ('p-1e17', 135), ('p-1e18', 229), ('p-1e19', 232), ('p-1e2', 289), ('p-1e20', 251), ('p-1e21', 317), ('p-1e22', 193), ('p-1e23', 249), ('p-1e24', 310), ('p-1e3', 223), ('p-1e4', 468), ('p-1e5', 232), ('p-1e6', 326), ('p-1e7', 407), ('p-1e8', 267), ('p0e14', 1), ('p0e15', 1), ('p0e20', 1), ('p0e6', 1), ('p0e7', 1), ('p2e0', 2), ('p2e1', 3), ('p2e10', 2), ('p2e11', 2), ('p2e12', 2), ('p2e13', 3), ('p2e14', 2), ('p2e15', 4), ('p2e16', 1), ('p2e17', 1), ('p2e18', 2), ('p2e19', 2), ('p2e2', 4), ('p2e20', 2), ('p2e21', 3), ('p2e22', 3), ('p2e23', 3), ('p2e24', 3), ('p2e3', 4), ('p2e4', 8), ('p2e5', 3), ('p2e6', 3), ('p2e7', 5), ('p2e8', 2), ('p3e0', 2), ('p3e1', 2), ('p3e10', 2), ('p3e11', 1), ('p3e12', 3), ('p3e13', 3), ('p3e14', 3), ('p3e15', 2), ('p3e16', 1), ('p3e17', 1), ('p3e19', 1), ('p3e2', 1), ('p3e20', 4), ('p3e21', 1), ('p3e22', 1), ('p3e23', 1), ('p3e24', 2), ('p3e3', 2), ('p3e4', 2), ('p3e5', 1), ('p3e6', 1), ('p3e7', 3), ('p3e8', 1), ('p4e0', 5), ('p4e1', 5), ('p4e10', 4), ('p4e11', 1), ('p4e12', 3), ('p4e13', 5), ('p4e14', 4), ('p4e15', 6), ('p4e17', 1), ('p4e18', 2), ('p4e19', 3), ('p4e2', 6), ('p4e20', 4), ('p4e21', 6), ('p4e22', 2), ('p4e23', 1), ('p4e24', 5), ('p4e3', 3), ('p4e4', 3), ('p4e5', 3), ('p4e6', 4), ('p4e7', 4), ('p4e8', 4), ('p5e0', 2), ('p5e10', 1), ('p5e12', 2), ('p5e21', 1), ('p5e3', 2), ('p5e4', 1), ('p5e8', 1), ('p6e0', 3), ('p6e1', 10), ('p6e10', 6), ('p6e11', 4), ('p6e12', 7), ('p6e13', 1), ('p6e14', 8), ('p6e15', 8), ('p6e16', 4), ('p6e17', 4), ('p6e18', 8), ('p6e19', 6), ('p6e2', 6), ('p6e20', 2), ('p6e21', 14), ('p6e22', 4), ('p6e23', 9), ('p6e24', 6), ('p6e3', 8), ('p6e4', 11), ('p6e5', 5), ('p6e6', 8), ('p6e7', 13), ('p6e8', 8), ('p7e1', 5), ('p7e10', 1), ('p7e11', 1), ('p7e12', 4), ('p7e15', 4), ('p7e16', 1), ('p7e17', 1), ('p7e18', 1), ('p7e2', 2), ('p7e21', 1), ('p7e22', 1), ('p7e23', 2), ('p7e24', 3), ('p7e4', 4), ('p7e5', 2), ('p7e6', 2), ('p7e7', 2), ('p7e8', 4), ('p8e0', 1), ('p8e10', 2), ('p8e12', 2), ('p8e14', 1), ('p8e18', 3), ('p8e21', 2), ('p8e22', 1), ('p8e24', 2), ('p8e3', 2), ('p8e5', 1), ('p8e6', 1), ('p8e8', 1), ('p9e0', 1), ('p9e1', 4), ('p9e10', 4), ('p9e12', 2), ('p9e13', 2), ('p9e14', 1), ('p9e15', 2), ('p9e16', 2), ('p9e17', 1), ('p9e18', 1), ('p9e19', 4), ('p9e2', 2), ('p9e20', 2), ('p9e21', 1), ('p9e22', 1), ('p9e23', 2), ('p9e24', 1), ('p9e3', 1), ('p9e4', 1), ('p9e6', 2), ('p9e7', 1)])\n",
      "final map is  {'8': '18', '-1': '4', '7': '1', '9': '19', '0': '7', '3': '20', '2': '4', '5': '3', '6': '21', '4': '21'}\n",
      "Accuracy of Kmeans with SIFT is  7.180702732849966 %\n"
     ]
    }
   ],
   "source": [
    "counts = collections.Counter(result)\n",
    "\n",
    "i = 0\n",
    "test_labels = []\n",
    "for d in des_test:\n",
    "    #print(\"shape is \", np.shape(d[0]))\n",
    "    num_keypts = np.shape(d[0])[0]\n",
    "    #print(\"i is \", i)\n",
    "    #print(\"num_keypts is \", inum_keypts)\n",
    "    labels = result[i: i+num_keypts]\n",
    "    i = i + num_keypts\n",
    "    #print (\"label each image \", labels)\n",
    "    #print (\"label each image \", len(labels))\n",
    "    test_labels.append(majority(labels, counts))\n",
    "#print(\"test labels for each image\", test_labels)\n",
    "#print(\"true labels \", data.test_y)\n",
    "label_map = {}\n",
    "err = 0\n",
    "acc = get_accuracy_cluster(data.test_y, test_labels)\n",
    "print(\"Accuracy of Kmeans with SIFT is \", acc, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plt.scatter(descriptors[:, 0], descriptors[:, 1], c=result, s=50, cmap='viridis')\n",
    "centers = kmeans.cluster_centers_\n",
    "plt.scatter(centers[:, 0], centers[:, 1], s=200, alpha=0.5);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start learning at 2018-12-08 23:21:14.787313\n",
      "Stop learning 2018-12-08 23:23:50.796798\n",
      "Elapsed learning 0:02:36.009485\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import datasets, svm, metrics\n",
    "import datetime as dt\n",
    "X_train, X_test, y_train, y_test = train_test_split(data.train_x, data.train_y, test_size=0.15, random_state=42)\n",
    "param_C = 5\n",
    "param_gamma = 0.05\n",
    "start_time = dt.datetime.now()\n",
    "print('Start learning at {}'.format(str(start_time)))\n",
    "classifier = svm.LinearSVC()\n",
    "#classifier = svm.SVC(C=param_C,gamma=param_gamma, decision_function_shape='ovo')\n",
    "\n",
    "classifier.fit(data.train_x, data.train_y)\n",
    "end_time = dt.datetime.now() \n",
    "print('Stop learning {}'.format(str(end_time)))\n",
    "elapsed_time= end_time - start_time\n",
    "print('Elapsed learning {}'.format(str(elapsed_time)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "expected = data.test_y\n",
    "predicted = classifier.predict(data.test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 60.75013943112103 %\n"
     ]
    }
   ],
   "source": [
    "#show_some_digits(X_test,predicted,title_text=\"Predicted {}\")\n",
    "\n",
    "#print(\"Classification report for classifier %s:\\n%s\\n\"\n",
    "      #% (classifier, metrics.classification_report(expected, predicted)))\n",
    "      \n",
    "#cm = metrics.confusion_matrix(expected, predicted)\n",
    "#print(\"Confusion matrix:\\n%s\" % cm)\n",
    "\n",
    "#plot_confusion_matrix(cm)\n",
    "\n",
    "print(\"Accuracy = {}\".format(metrics.accuracy_score(expected, predicted) * 100) + \" %\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27455\n",
      "184773\n"
     ]
    }
   ],
   "source": [
    "print(len(des[:,1]))\n",
    "descriptors = extract_descriptors(des)\n",
    "print(len(descriptors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = []\n",
    "i = 0\n",
    "c = 0\n",
    "for d in des:\n",
    "    #print(\"shape is \", np.shape(d[0]))\n",
    "    num_keypts = np.shape(d[0])[0]\n",
    "    #print(\"i is \", i)\n",
    "    #print(\"num_keypts is \", num_keypts)\n",
    "    #print(\"label is \", d[1])\n",
    "    for j in range(num_keypts):\n",
    "        #print(d[1])\n",
    "        train_labels.append(d[1])\n",
    "    \n",
    "    i = i+num_keypts\n",
    "    #labels = result[i: i+num_keypts]\n",
    "    #i = i + num_keypts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "193536\n",
      "193536\n",
      "184773\n",
      "15\n"
     ]
    }
   ],
   "source": [
    "print(i)\n",
    "print(len(train_labels))\n",
    "print(len(descriptors))\n",
    "print(train_labels[184772])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start learning at 2018-12-13 21:36:09.316940\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-262-d3b93ff45e15>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m#classifier = svm.SVC(C=param_C,gamma=param_gamma, decision_function_shape='ovo')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdescriptors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m184773\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mend_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Stop learning {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.5/site-packages/sklearn/svm/classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    233\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpenalty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdual\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmulti_class\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 235\u001b[0;31m             self.loss, sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    236\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmulti_class\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"crammer_singer\"\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.5/site-packages/sklearn/svm/base.py\u001b[0m in \u001b[0;36m_fit_liblinear\u001b[0;34m(X, y, C, fit_intercept, intercept_scaling, class_weight, penalty, dual, verbose, max_iter, tol, random_state, multi_class, loss, epsilon, sample_weight)\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_ind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misspmatrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msolver_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    889\u001b[0m         \u001b[0mclass_weight_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrnd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'i'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 890\u001b[0;31m         epsilon, sample_weight)\n\u001b[0m\u001b[1;32m    891\u001b[0m     \u001b[0;31m# Regarding rnd.randint(..) in the above signature:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    892\u001b[0m     \u001b[0;31m# seed for srand in range [0..INT_MAX); due to limitations in Numpy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(descriptors, train_labels[0:184773], test_size=0.15, random_state=42)\n",
    "param_C = 5\n",
    "param_gamma = 0.05\n",
    "start_time = dt.datetime.now()\n",
    "print('Start learning at {}'.format(str(start_time)))\n",
    "classifier = svm.LinearSVC()\n",
    "#classifier = svm.SVC(C=param_C,gamma=param_gamma, decision_function_shape='ovo')\n",
    "\n",
    "classifier.fit(descriptors, train_labels[0:184773])\n",
    "end_time = dt.datetime.now() \n",
    "print('Stop learning {}'.format(str(end_time)))\n",
    "elapsed_time= end_time - start_time\n",
    "print('Elapsed learning {}'.format(str(elapsed_time)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48899\n",
      "193536\n",
      "184773\n"
     ]
    }
   ],
   "source": [
    "descriptors_test = extract_descriptors(des_test)\n",
    "test_labels = []\n",
    "i = 0\n",
    "c = 0\n",
    "for d in des_test:\n",
    "    #print(\"shape is \", np.shape(d[0]))\n",
    "    num_keypts = np.shape(d[0])[0]\n",
    "    #print(\"i is \", i)\n",
    "    #print(\"num_keypts is \", num_keypts)\n",
    "    #print(\"label is \", d[1])\n",
    "    for j in range(num_keypts):\n",
    "        #print(d[1])\n",
    "        test_labels.append(d[1])\n",
    "    \n",
    "    i = i+num_keypts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48899\n",
      "48899\n",
      "47883\n",
      "7172\n"
     ]
    }
   ],
   "source": [
    "print(i)\n",
    "print(len(test_labels))\n",
    "print(len(descriptors_test))\n",
    "print(len(data.test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "expected = test_labels\n",
    "predicted = classifier.predict(descriptors_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy=3.867761000772717%\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy={}\".format(metrics.accuracy_score(expected[0:47883], predicted) * 100) + \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sklearn skimage\n",
    "from skimage import feature\n",
    "\n",
    "# Histogram of Oriented Gradients\n",
    "class HOG:\n",
    "\tdef __init__(self, orientations = 9, pixelsPerCell = (9, 9),\n",
    "\t\tcellsPerBlock = (3, 3), block_norm = 'L2-Hys'):  \n",
    "\t\tself.orientations = orientations\n",
    "\t\tself.pixelsPerCell = pixelsPerCell\n",
    "\t\tself.cellsPerBlock = cellsPerBlock\n",
    "\t\tself.block_norm = block_norm    # changing from default to L2-Hys, improved a lot\n",
    "\n",
    "\tdef describe(self, image):\n",
    "\t\t# compute HOG for the image\n",
    "\t\thist = feature.hog(image, orientations = self.orientations,\n",
    "\t\t\tpixels_per_cell = self.pixelsPerCell,\n",
    "\t\t\tcells_per_block = self.cellsPerBlock,\n",
    "\t\t\tblock_norm = self.block_norm) \n",
    "\n",
    "\t\t# return the HOG features\n",
    "\t\treturn hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import cv2\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "from skimage import color\n",
    "from skimage.feature import hog\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import classification_report,accuracy_score\n",
    "\n",
    "\n",
    "ppc = 16\n",
    "hog_images = []\n",
    "hog_features = []\n",
    "i = 0\n",
    "hog = HOG(orientations = 3, pixelsPerCell = (2, 2),cellsPerBlock = (4, 4), block_norm = 'L2-Hys')\n",
    "hist_data = []  \n",
    "for x,y in zip(data.train_x, data.train_y):\n",
    "    if (y in [0,1,2,5,7,11,14,15,19,21]):\n",
    "        fname = \"img{}\".format(i)+\".jpg\"\n",
    "        cv2.imwrite(fname, x.reshape(28,28))\n",
    "        img = cv2.imread(fname)\n",
    "        os.remove(fname)\n",
    "        gray= cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        #fd,hog_image = hog(gray, orientations=8, pixels_per_cell=(ppc,ppc),cells_per_block=(4, 4),block_norm= 'L2')\n",
    "        hist = hog.describe(gray)\n",
    "        hist_data.append(hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11290, 5808)\n",
      "11290\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(hist_data))\n",
    "print(len(hist_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_data_test = []  \n",
    "for x,y in zip(data.test_x, data.test_y):\n",
    "    if (y in [0,1,2,5,7,11,14,15,19,21]):\n",
    "        fname = \"img{}\".format(i)+\".jpg\"\n",
    "        cv2.imwrite(fname, x.reshape(28,28))\n",
    "        img = cv2.imread(fname)\n",
    "        os.remove(fname)\n",
    "        gray= cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        #fd,hog_image = hog(gray, orientations=8, pixels_per_cell=(ppc,ppc),cells_per_block=(4, 4),block_norm= 'L2')\n",
    "        hist = hog.describe(gray)\n",
    "        hist_data_test.append(hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_few = []\n",
    "for y in data.train_y:\n",
    "    if (y in [0,1,2,5,7,11,14,15,19,21]):\n",
    "        true_few.append(y)\n",
    "expected = []\n",
    "for y in data.test_y:\n",
    "    if (y in [0,1,2,5,7,11,14,15,19,21]):\n",
    "        expected.append(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "kmeans = KMeans(n_clusters=10).fit(hist_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = kmeans.predict(hist_data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total errors  2281\n",
      "Accuracy of Kmeans with HOG with 10 lables is  27.633248730964468 %\n"
     ]
    }
   ],
   "source": [
    "label_map = {}\n",
    "err = 0\n",
    "for true_label, pred_label in zip(expected, result):\n",
    "    if true_label not in label_map:\n",
    "        label_map[true_label] = pred_label\n",
    "    else:\n",
    "        if label_map[true_label] != pred_label and pred_label != -1:\n",
    "            err = err +1\n",
    "print(\"Total errors \", err)  \n",
    "print(\"Accuracy of Kmeans with HOG with 10 lables is \", 100- err*100/len(result), \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "few_train = []\n",
    "for x,y in zip(data.train_x, data.train_y):\n",
    "    if (y in [0,1,2,5,7,11,14,15,19,21]):\n",
    "        few_train.append(x)\n",
    "few_test = []\n",
    "for x,y in zip(data.test_x, data.test_y):\n",
    "    if (y in [0,1,2,5,7,11,14,15,19,21]):\n",
    "        few_test.append(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "kmeans = KMeans(n_clusters=10).fit(few_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total errors  2281\n",
      "Accuracy of Kmeans without HOG with 10 lables is  27.633248730964468 %\n"
     ]
    }
   ],
   "source": [
    "result = kmeans.predict(few_test)\n",
    "label_map = {}\n",
    "err = 0\n",
    "for true_label, pred_label in zip(expected, result):\n",
    "    if true_label not in label_map:\n",
    "        label_map[true_label] = pred_label\n",
    "    else:\n",
    "        if label_map[true_label] != pred_label and pred_label != -1:\n",
    "            err = err +1\n",
    "print(\"Total errors \", err)  \n",
    "print(\"Accuracy of Kmeans without HOG with 10 lables is \", 100- err*100/len(result), \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0)"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = svm.LinearSVC()\n",
    "classifier.fit(hist_data, true_few)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = classifier.predict(hist_data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of SVM with HOG 10 labels =96.06598984771574 %\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy of SVM with HOG 10 labels ={}\".format(metrics.accuracy_score(expected, predicted) * 100) + \" %\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start learning at 2018-12-11 11:49:22.115200\n",
      "Stop learning 2018-12-11 11:51:18.464806\n",
      "Elapsed learning 0:01:56.349606\n"
     ]
    }
   ],
   "source": [
    "from sklearn.mixture import GaussianMixture\n",
    "start_time = dt.datetime.now()\n",
    "print('Start learning at {}'.format(str(start_time)))\n",
    "gmm = GaussianMixture(n_components=10).fit(few_train)\n",
    "end_time = dt.datetime.now() \n",
    "print('Stop learning {}'.format(str(end_time)))\n",
    "elapsed_time= end_time - start_time\n",
    "print('Elapsed learning {}'.format(str(elapsed_time)))\n",
    "#labels = gmm.predict(hist_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total errors  1499\n",
      "Accuracy of GMM with 10 labels is  52.442893401015226 %\n"
     ]
    }
   ],
   "source": [
    "labels = gmm.predict(few_test)\n",
    "label_map = {}\n",
    "err = 0\n",
    "for true_label, pred_label in zip(expected, labels):\n",
    "    if true_label not in label_map:\n",
    "        label_map[true_label] = pred_label\n",
    "    else:\n",
    "        if label_map[true_label] != pred_label and pred_label != -1:\n",
    "            err = err +1\n",
    "print(\"Total errors \", err)  \n",
    "print(\"Accuracy of GMM with 10 labels is \", 100- err*100/len(result), \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start learning at 2018-12-11 11:52:08.484395\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-238-c81c389f67b3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Start learning at {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mgmm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGaussianMixture\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_components\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhist_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mend_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Stop learning {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.5/site-packages/sklearn/mixture/base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m                 \u001b[0mlog_prob_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_resp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_e_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 214\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_m_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_resp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    215\u001b[0m                 self.lower_bound_ = self._compute_lower_bound(\n\u001b[1;32m    216\u001b[0m                     log_resp, log_prob_norm)\n",
      "\u001b[0;32m~/anaconda3/lib/python3.5/site-packages/sklearn/mixture/gaussian_mixture.py\u001b[0m in \u001b[0;36m_m_step\u001b[0;34m(self, X, log_resp)\u001b[0m\n\u001b[1;32m    669\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights_\u001b[0m \u001b[0;34m/=\u001b[0m \u001b[0mn_samples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    670\u001b[0m         self.precisions_cholesky_ = _compute_precision_cholesky(\n\u001b[0;32m--> 671\u001b[0;31m             self.covariances_, self.covariance_type)\n\u001b[0m\u001b[1;32m    672\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    673\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_estimate_log_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.5/site-packages/sklearn/mixture/gaussian_mixture.py\u001b[0m in \u001b[0;36m_compute_precision_cholesky\u001b[0;34m(covariances, covariance_type)\u001b[0m\n\u001b[1;32m    316\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcovariance\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcovariances\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 318\u001b[0;31m                 \u001b[0mcov_chol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcholesky\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcovariance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlower\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    319\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinAlgError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimate_precision_error_message\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.5/site-packages/scipy/linalg/decomp_cholesky.py\u001b[0m in \u001b[0;36mcholesky\u001b[0;34m(a, lower, overwrite_a, check_finite)\u001b[0m\n\u001b[1;32m     89\u001b[0m     \"\"\"\n\u001b[1;32m     90\u001b[0m     c, lower = _cholesky(a, lower=lower, overwrite_a=overwrite_a, clean=True,\n\u001b[0;32m---> 91\u001b[0;31m                          check_finite=check_finite)\n\u001b[0m\u001b[1;32m     92\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.5/site-packages/scipy/linalg/decomp_cholesky.py\u001b[0m in \u001b[0;36m_cholesky\u001b[0;34m(a, lower, overwrite_a, clean, check_finite)\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;34m\"\"\"Common code for cholesky() and cho_factor().\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0ma1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0masarray_chkfinite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcheck_finite\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0ma1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0matleast_2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.5/site-packages/numpy/lib/function_base.py\u001b[0m in \u001b[0;36masarray_chkfinite\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m   1229\u001b[0m     \"\"\"\n\u001b[1;32m   1230\u001b[0m     \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1231\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchar\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtypecodes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'AllFloat'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfinite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1232\u001b[0m         raise ValueError(\n\u001b[1;32m   1233\u001b[0m             \"array must not contain infs or NaNs\")\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.mixture import GaussianMixture\n",
    "start_time = dt.datetime.now()\n",
    "print('Start learning at {}'.format(str(start_time)))\n",
    "gmm = GaussianMixture(n_components=10).fit(hist_data)\n",
    "end_time = dt.datetime.now() \n",
    "print('Stop learning {}'.format(str(end_time)))\n",
    "elapsed_time= end_time - start_time\n",
    "print('Elapsed learning {}'.format(str(elapsed_time)))\n",
    "#labels = gmm.predict(hist_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
